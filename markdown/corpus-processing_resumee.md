# Resümee

```{admonition} Key points des Kapitels
:class: keypoint
**Von Text zu linguistischer Information**

Die Verarbeitung von Text mittels [NLP](corpus-processing_intro-to-nlp.html#was-ist-nlp-und-warum-benutzen-wir-es) ermöglicht die Anreicherung mit linguistischen Informationen und schafft damit die Grundlage für semantische Analysen. Aus einer reinen Zeichenkette werden strukturierte, analysierbare Texteinheiten.

**Methodische Grundlagen**

Die vorgestellten [NLP-Methoden](corpus-processing_intro-to-nlp.html#verwendete-nlp-methoden) - Tokenisierung und Lemmatisierung - bilden die Basis für weiterführende Textanalysen. Der Vergleich zwischen einfacher Worttrennung und professioneller Tokenisierung zeigt dabei die Bedeutung spezialisierter NLP-Tools.

**Praktische Umsetzung**

Mit spaCy steht ein effizientes Werkzeug zur [systematischen Korpusverarbeitung](../nlp-enrichment/NLP-Enrichment) zur Verfügung, das die Annotation großer Textmengen ermöglicht und die Grundlage für quantitative Analysen schafft.
```

<!-- 
In diesem Kapitel wurde eine Übersicht über eine [Auswahl an Methoden des Natural Language Processing](corpus-processing-intro-2) gegeben (Tokenisierung, Lemmatisierung) und es wurde gezeigt, wie diese durch die Python-Bibliothek spaCy auf ein Textkorpus angewendet werden können. 
Im nächsten Schritt kann auf Grundlage der Token und Lemma das Korpus an Hand von Worthäufigkeiten analysiert werden. 
-->