{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dc89c3",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d0e29",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we'll take the CONLL data and do some analysis. Like \n",
    "* plot the frequencies of some lemma\n",
    "* look at some lemmas contexts\n",
    "* analyze some lemmas collocations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a267e",
   "metadata": {},
   "source": [
    "## 0. Imports and data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8dd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conllfiles = (r\"../data/conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fa9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_annotations = {}\n",
    "for filename in os.listdir(conllfiles):\n",
    "    if '.conll' in filename:\n",
    "        path = os.path.join(conllfiles, filename)  \n",
    "        data = pd.read_csv(path) \n",
    "        corpus_annotations[filename] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3da39",
   "metadata": {},
   "source": [
    "## 1. Search lemma and plot frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordSearchEngine:\n",
    "    \n",
    "    def __init__(self, corpus_annotated):\n",
    "        self.prepare_index_dataframe_for_search(corpus_annotated)\n",
    "    \n",
    "    def prepare_index_dataframe_for_search(self, corpus_annotated):\n",
    "        for filename, annotated_text in corpus_annotated.items():\n",
    "            year, month, day = self.get_date_fname(filename)\n",
    "            annotated_text['month'] = month\n",
    "        self.full_df = pd.concat(corpus_annotated.values())\n",
    "        print(f'Searching in a corpus of {self.full_df.shape[0]} word occurences')\n",
    "        \n",
    "    def get_date_fname(self, filename):  ## REDO WITH METADATA\n",
    "        date_pattern = re.search(r'(19\\d\\d)(\\d\\d)(\\d\\d)-0-0-0-0', filename)\n",
    "        year = date_pattern.group(1)\n",
    "        month = f'{year}-{date_pattern.group(2)}'\n",
    "        day =  f'{month}-{date_pattern.group(3)}'\n",
    "        return year, month, day    \n",
    "        \n",
    "    def search_and_plot(self):\n",
    "        search_term = input('Insert a word to search: ')\n",
    "        if len(search_term) == 0:\n",
    "            search_term = 'Grippe'\n",
    "        result = self.full_df.query(f'Lemma==\"{search_term}\"')\n",
    "        result.groupby('month').count().Lemma.plot(title=f'frequency of {search_term}');\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = WordSearchEngine(corpus_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.search_and_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2a08b",
   "metadata": {},
   "source": [
    "## 2. Exploring the contexts\n",
    "\n",
    "Let us look at the contexts in which the words appear\n",
    "\n",
    "\n",
    "### 2.1 KWIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9684f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextViewer:\n",
    "    \n",
    "    def __init__(self, corpus_annotated):\n",
    "        self.full_df = self.prepare_index_dataframe_for_search(corpus_annotated)\n",
    "        self.full_df = self.full_df.reset_index()\n",
    "        #print(type(self.full_df))\n",
    "        \n",
    "    def prepare_index_dataframe_for_search(self, corpus_annotated):\n",
    "        for filename, annotated_text in corpus_annotated.items():\n",
    "            year, month, day = self.get_date_fname(filename)\n",
    "            annotated_text['month'] = month\n",
    "        return pd.concat(corpus_annotated.values())\n",
    "        #print(f'Searching in a corpus of {self.full_df.shape[0]} word occurences')\n",
    "        \n",
    "    def get_date_fname(self, filename): ## REDO WITH METADATA\n",
    "        date_pattern = re.search(r'(19\\d\\d)(\\d\\d)(\\d\\d)-0-0-0-0', filename)\n",
    "        year = date_pattern.group(1)\n",
    "        month = f'{year}-{date_pattern.group(2)}'\n",
    "        day =  f'{month}-{date_pattern.group(3)}'\n",
    "        return year, month, day    \n",
    "        \n",
    "    def get_context(self):\n",
    "        search_lemma = input('Insert a word to search: ')\n",
    "        if len(search_lemma) == 0:\n",
    "            search_lemma = 'Grippe'\n",
    "        indices = self.full_df.query(f'Lemma==\"{search_lemma}\"').index\n",
    "        #print(indices)\n",
    "        left_contexts = []\n",
    "        this_words = []\n",
    "        right_contexts = []\n",
    "        months = []\n",
    "        for indice in indices:\n",
    "            left = self.full_df.iloc[indice-10:indice-1, ][\"Token\"]\n",
    "            leftс = left[~left.str.contains('\\n')]\n",
    "            right = self.full_df.iloc[indice+1:indice+10, ][\"Token\"]\n",
    "            rightс = right[~right.str.contains('\\n')]\n",
    "            left_contexts.append(' '.join(leftс))\n",
    "            right_contexts.append(' '.join(rightс))\n",
    "            this_words.append(self.full_df.iloc[indice, ][\"Token\"])\n",
    "            months.append(self.full_df.iloc[indice, ][\"month\"])\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['left_context'] = left_contexts\n",
    "        newdf['word'] = this_words\n",
    "        newdf['right_context'] = right_contexts\n",
    "        newdf['month'] = months\n",
    "        return newdf #.sort_values(by='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec93d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic = ContextViewer(corpus_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7441e7",
   "metadata": {},
   "source": [
    "### 2.2 Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60370142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
